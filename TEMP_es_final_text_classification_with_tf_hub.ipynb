{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEMP-es-final-text_classification_with_tf_hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Skyblueballykid/RIIAA-18/blob/master/TEMP_es_final_text_classification_with_tf_hub.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "N6ZDpd9XzFeN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Derechos reservados 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licencia bajo Apache License, Version 2.0 (la \"Licencia\");"
      ]
    },
    {
      "metadata": {
        "id": "KUu4vOt5zI9d",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ok9PfyoQ2rH_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cómo construir un simple clasificador con TF-Hub\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver el código fuente en GitHub</a>\n",
        "</td></table>\n"
      ]
    },
    {
      "metadata": {
        "id": "AK3mz3JNMW8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TF-Hub es una plataforma para compartir incorporaciones (embeddings) de aprendizaje automático previamente entrenadas y reusables por medio de **módulos**. Este tutorial está organizado en dos partes principales.\n",
        "\n",
        "** *Introducción*: entrenamiento de un clasificador de texto con TF-Hub**\n",
        "\n",
        "Utilizaremos un módulo de incorporaciones de texto previamente entrenadas de TF-Hub para entrenar un clasificador de sentimiento simple con una exactitud razonable, comparada con el modelo de referencia. Después analizaremos las predicciones para asegurarnos de que nuestro modelo sea razonable y proponer mejoras para aumentar la exactitud.\n",
        "\n",
        "** *Avanzado*: análisis de aprendizaje por transferencia**\n",
        "\n",
        "En esta sección, utilizaremos varios módulos de TF-Hub para comparar su efecto en la precisión del estimador y demostrar las ventajas y dificultades del aprendizaje por transferencia.\n"
      ]
    },
    {
      "metadata": {
        "id": "aYVd26q1_3xW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Requisitos previos opcionales\n",
        "\n",
        "* Conocimiento básico de la [API del estimador prediseñado](https://www.tensorflow.org/get_started/premade_estimators) de Tensorflow.\n",
        "* Conocimiento básico de la librería Pandas.\n"
      ]
    },
    {
      "metadata": {
        "id": "xOATihhH1IxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparando el entorno"
      ]
    },
    {
      "metadata": {
        "id": "_8N3Hx2dyUC-",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "# Instale la versión más reciente de Tensorflow.\n",
        "!pip install --quiet \"tensorflow>=1.7\"\n",
        "# Instale TF-Hub.\n",
        "!pip install tensorflow-hub\n",
        "!pip install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRXN9a8Mz8e-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se puede encontrar información más detallada sobre la instalación de Tensorflow en [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "metadata": {
        "id": "v7hy0bhngTUp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OPyVxHuiTEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Empezando\n",
        "\n",
        "## Datos\n",
        "Intentaremos resolver la tarea [Base de datos de reseñas de películas v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) de Mass et al. La base de datos consiste en reseñas de películas de IMDB etiquetadas por polaridad (qué tan positivas o negativas) del 1 al 10. La tarea es etiquetar las reseñas como **negativo** o **positivo**."
      ]
    },
    {
      "metadata": {
        "id": "rKzc-fOGV72G",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Cargue todos los archivos del directorio en un DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Combina los ejemplos positivos y negativos, agrega una columna de polaridad y \n",
        "# cambia el order de forma aleatoria.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Descargue y procese los archivos de datos.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "# Reduce el nivel de detalle en los mensajes (verbosity).\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "train_df, test_df = download_and_load_datasets()\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9Xq4x1mU3un",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modelo\n",
        "### Atributos de entrada (input functions)\n",
        "\n",
        "[La API del estimador](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) proporciona [atributos de entrada](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) que provee un capa de abstracción sobre los objetos DataFrame de Pandas."
      ]
    },
    {
      "metadata": {
        "id": "25rdoEHih0fm",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Configura la entrada de entrenamiento (training input) en todo el conjunto de\n",
        "# entrenamiento (training set) sin repeticiones (epochs) de entrenamiento.\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
        "\n",
        "# Configura la predicción en todo el conjunto de entrenamiento.\n",
        "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], shuffle=False)\n",
        "# Configura la predicción en todo el conjunto de prueba (test set).\n",
        "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    test_df, test_df[\"polarity\"], shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uyl6YGRcVAwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Columnas de atributos\n",
        "\n",
        "TF-Hub proporciona una [columna de atributos](https://github.com/tensorflow/hub/blob/master/docs/api_docs/python/hub/text_embedding_column.md) que aplica un módulo a un atributo de texto y conecta las salidas del módulo. En este tutorial usaremos el módulo [nnlm-en-dim128](https://tfhub.dev/google/nnlm-en-dim128/1). Para fines de este tutorial, los aspectos más importantes son:\n",
        "\n",
        "* El módulo toma **un lote de oraciones en un tensor 1-D de cadenas de caracteres (string)** como entrada.\n",
        "* El módulo es responsable del **preprocesamiento de oraciones** (por ejemplo, eliminación de signos de puntuación y usar espacios para dividir palabras).\n",
        "* El módulo funciona con cualquier entrada (por ejemplo **nhlm-en-dim128** agrupa palabras no presentes en el vocabulario en ~ 20.000 grupos)."
      ]
    },
    {
      "metadata": {
        "id": "X7vyvj-hDEXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedded_text_feature_column = hub.text_embedding_column(\n",
        "    key=\"sentence\", \n",
        "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPuHgx3BWBOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Estimador\n",
        "\n",
        "Para la clasificación podemos usar un [clasificador neuronal profundo](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (tome en cuenta que al final del tutorial proporcionamos información adicional sobre de varias funciones de etiquetado para los modelos)."
      ]
    },
    {
      "metadata": {
        "id": "23U30yEkVq4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.estimator.DNNClassifier(\n",
        "    hidden_units=[500, 100],\n",
        "    feature_columns=[embedded_text_feature_column],\n",
        "    n_classes=2,\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-O_k-8jgWPXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento\n",
        "\n",
        "Entrena al estimador durante una cantidad razonable de pasos."
      ]
    },
    {
      "metadata": {
        "id": "e5uDRv1r7Ed4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Entrenar 1,000 pasos significa procesar 128,000 ejemplos de entrenamiento con\n",
        "# el tamaño del lote determinado (default). Esto es más o menos equivalente a 5\n",
        "# repeticiones, ya que el conjunto de entrenamiento solo contiene 25,000\n",
        "# ejemplos.\n",
        "estimator.train(input_fn=train_input_fn, steps=1000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8j7YTRSe7Pj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicción\n",
        "\n",
        "Genera predicciones tanto para el conjunto de entrenamiento como para el conjunto de prueba."
      ]
    },
    {
      "metadata": {
        "id": "zbLg5LzGwAfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
        "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
        "\n",
        "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
        "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DR2IsTF5vuAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Matriz de confusión\n",
        "\n",
        "Podemos verificar visualmente la matriz de confusión para entender la distribución de las clasificaciones erróneas."
      ]
    },
    {
      "metadata": {
        "id": "nT71CtArpsKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_predictions(estimator, input_fn):\n",
        "  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
        "\n",
        "LABELS = [\n",
        "    \"negative\", \"positive\"\n",
        "]\n",
        "\n",
        "# Crea una matriz de confusión para el conjunto entrenamiento.\n",
        "with tf.Graph().as_default():\n",
        "  cm = tf.confusion_matrix(train_df[\"polarity\"], \n",
        "                           get_predictions(estimator, predict_train_input_fn))\n",
        "  with tf.Session() as session:\n",
        "    cm_out = session.run(cm)\n",
        "\n",
        "# Normaliza la matriz de confusión para que cada fila sume 1.\n",
        "cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
        "plt.xlabel(\"Predicted\");\n",
        "plt.ylabel(\"True\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sG-ES55Ftp-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Futuras mejoras\n",
        "\n",
        "1. **Usar un modelo de regresión**: aunque utilizamos un modelo de clasificación para asignar cada ejemplo a una clase que representa la polaridad de una reseña, en realidad tenemos otra característica categórica a nuestra disposición: el sentimiento. Aquí las clases discretas realmente representan una _escala_ y el valor subyacente (positivo / negativo) podría mapearse en un rango de _valores continuos_. Podríamos hacer uso de esta propiedad calculando una regresión ([DNN Regressor](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNRegressor)) en lugar de una clasificación ([DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier)).\n",
        "2. **Usar un módulo más grande**: en este tutorial usamos un pequeño módulo para restringir el uso de la memoria. Pero hay módulos con vocabularios e incorporaciones más grandes que podrían incrementar la exactitud del modelo.\n",
        "3. **Ajustar otros parámetros**: podemos mejorar la exactitud ajustando los hiperparámetros, como la tasa de aprendizaje o la cantidad de pasos, especialmente si utilizamos un módulo diferente. Tener a la mano un conjunto de validación es también muy importante si queremos obtener resultados razonables, ya que es muy fácil configurar un modelo que aprende a predecir los datos del conjunto de entrenamiento sin generalizar bien al conjunto de prueba.\n",
        "4. **Entrenar un modelo más complejo**: en este tutorial utilizamos un módulo que calcula incorporaciones de oraciones al incorporar cada palabra de manera individual y después las combina calculando un promedio. Alternativamente, se podría usar un módulo secuencial (por ejemplo, el módulo [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/2)) para captar mejor el significado de las oraciones, o inclusive combinar dos o más módulos de TF-Hub.\n",
        "5. **Regularización**: para evitar un sobreajuste, podríamos tratar de usar un optimizador que realice algún tipo de regularización, por ejemplo, el [Optimizador Proximal Adagrad](https://www.tensorflow.org/api_docs/python/tf/train/ProximalAdagradOptimizer)."
      ]
    },
    {
      "metadata": {
        "id": "fKRNsaO8L50F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Avanzado: análisis de aprendizaje por transferencia\n",
        "\n",
        "El aprendizaje por transferencia permite **ahorrar recursos de entrenamiento** y lograr una buena generalización del modelo incluso cuando se entrena con un número reducido de datos. En esta parte, demostraremos esa idea entrenando con dos módulos TF-Hub diferentes:\n",
        "\n",
        "* **[nnlm-en-dim128](https://tfhub.dev/google/nnlm-en-dim128/1)** - módulo de incorporaciones de texto previamente entrenado,\n",
        "* **[random-nnlm-en-dim128](https://tfhub.dev/google/random-nnlm-en-dim128/1)** - módulo de incorporaciones de texto que tiene el mismo vocabulario y red que **nnlm-en-dim128**, pero los pesos se inicializaron aleatoriamente y nunca se entrenaron con datos reales.\n",
        "\n",
        "Y entrenando en dos modos:\n",
        "\n",
        "* entrenar **solo el clasificador** (es decir, congelar el módulo), y\n",
        "* entrenando el **clasificador junto con el módulo**.\n",
        "\n",
        "Entrenemos y evaluemos un par de experimentos para ver cómo el uso de varios módulos puede afectar la exactitud."
      ]
    },
    {
      "metadata": {
        "id": "AWYa1So1ARyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_with_module(hub_module, train_module=False):\n",
        "  embedded_text_feature_column = hub.text_embedding_column(\n",
        "      key=\"sentence\", module_spec=hub_module, trainable=train_module)\n",
        "\n",
        "  estimator = tf.estimator.DNNClassifier(\n",
        "      hidden_units=[500, 100],\n",
        "      feature_columns=[embedded_text_feature_column],\n",
        "      n_classes=2,\n",
        "      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, steps=1000)\n",
        "\n",
        "  train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
        "  test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
        "\n",
        "  training_set_accuracy = train_eval_result[\"accuracy\"]\n",
        "  test_set_accuracy = test_eval_result[\"accuracy\"]\n",
        "\n",
        "  return {\n",
        "      \"Training accuracy\": training_set_accuracy,\n",
        "      \"Test accuracy\": test_set_accuracy\n",
        "  }\n",
        "\n",
        "\n",
        "results = {}\n",
        "results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "results[\"nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128/1\", True)\n",
        "results[\"random-nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\")\n",
        "results[\"random-nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\", True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsWppYMphIPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Veamos los resultados."
      ]
    },
    {
      "metadata": {
        "id": "UVkdErEKkIXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(results, orient=\"index\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z9rZ2fuGfUFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ya podemos ver algunos patrones, pero primero debemos establecer la exactitud de referencia del conjunto de prueba - el límite inferior que se puede lograr al generar solo la etiqueta de la clase más común:"
      ]
    },
    {
      "metadata": {
        "id": "IgYPVvc3G6OS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=predict_test_input_fn)[\"accuracy_baseline\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UN4D-DPPrINX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El asignar la clase más común nos dará una exactitud del **50%**. Hay un par de cosas que resaltar:\n",
        "\n",
        "1. Quizás de manera sorprendente, **un modelo pueda aprender aún usando incorporaciones fijas y aleatorias**. La razón es que incluso si cada palabra en el diccionario se asigna a un vector aleatorio, el estimador puede separar el espacio utilizando únicamente sus capas completamente conectadas.\n",
        "2. Permitir el entrenamiento del módulo con **incorporaciones aleatorias** (y no solo del clasificador) aumenta tanto la exactitud de entrenamiento *y* la de prueba.\n",
        "3. El entrenamiento del módulo con **incorporaciones previamente entrenadas** también aumenta ambas excactitudes. Sin embargo, hay que tener en cuenta que puede causar un sobreajuste al conjunto de entrenamiento. El entrenamiento de un módulo preentrenado puede ser riesgoso incluso con la regularización en el sentido de que los pesos de las incorporaciones dejarán de representar al modelo de lenguaje entrenado en datos diversos, sino que convergirán en la representación ideal del nuevo conjunto de datos."
      ]
    }
  ]
}